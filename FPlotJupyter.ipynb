{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b06a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import random\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b485fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_table = pd.read_excel('ALS_table.xlsx', converters={'Subject code':str})\n",
    "ALS_codes = ALS_table.get('Subject code')\n",
    "HC_table = pd.read_excel('HC_table.xlsx', converters={'Subject code':str})\n",
    "HC_codes = HC_table.get('Subject code')\n",
    "data_dirALS = str(pathlib.Path('ALS'))\n",
    "data_dirHC = str(pathlib.Path('HC'))\n",
    "filenamesALS = tf.io.gfile.glob(data_dirALS + '/*')\n",
    "filenamesHC = tf.io.gfile.glob(data_dirHC + '/*')\n",
    "dataset_X = []\n",
    "spectrograms = []\n",
    "dataset_Y = []\n",
    "dataset = []\n",
    "HC_dataset = []\n",
    "filenames = []\n",
    "filenames = np.append(filenames, filenamesALS)\n",
    "filenames = np.append(filenames, filenamesHC)\n",
    "classes = ['ALS', 'HC']\n",
    "filenames.sort()\n",
    "print(len(filenamesALS))\n",
    "print(len(filenamesHC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33497564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "    if len(spectrogram.shape) > 2:\n",
    "        assert len(spectrogram.shape) == 3\n",
    "        spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b204b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label(filepath):\n",
    "  audioFile = tf.io.read_file(filepath)\n",
    "  waveform = tf.audio.decode_wav(contents=audioFile, desired_samples=44100*3)\n",
    "  waveform = tf.squeeze(waveform.audio, axis=-1)\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "  parts = tf.strings.split(\n",
    "    input=filepath,\n",
    "    sep=os.path.sep)\n",
    "  label = tf.argmax(parts[-2] == classes)\n",
    "  return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_spectrogram_and_label(filepath):\n",
    "  audioFile = tf.io.read_file(filepath)\n",
    "  waveform = tf.audio.decode_wav(contents=audioFile, desired_samples=44100*3)\n",
    "  waveform = tf.squeeze(waveform.audio, axis=-1)\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  spectrogram = get_mel_spectrogram(waveform)\n",
    "  parts = tf.strings.split(\n",
    "    input=filepath,\n",
    "    sep=os.path.sep)\n",
    "  label = tf.argmax(parts[-2] == classes)\n",
    "  return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_spectrogram(waveform):\n",
    "  stfts = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "  spectrograms = tf.abs(stfts)\n",
    "  num_spectrogram_bins = stfts.shape[-1]\n",
    "  lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20, 20000, 80\n",
    "  linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix( num_mel_bins, num_spectrogram_bins, 44100.0, lower_edge_hertz, upper_edge_hertz)\n",
    "  mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "  mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "  # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "  log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "  # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "  mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :13]\n",
    "  return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFile = tf.io.read_file('ALS/055_a.wav')\n",
    "waveform = tf.audio.decode_wav(contents=audioFile, desired_samples=44100*3)\n",
    "waveform = tf.squeeze(waveform.audio, axis=-1)\n",
    "waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "spectrogram = get_spectrogram(waveform)\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 44100*3])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "axes[1].set_xlim([0, 44100*3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteraciones = 10\n",
    "EPOCHS = 50\n",
    "sizeTrain = 178\n",
    "sizeVal = 38\n",
    "sizeTest = 254 - sizeTrain - sizeVal\n",
    "average = []\n",
    "for iteracion in range(iteraciones):\n",
    "    contTrain = 0\n",
    "    contVal = 0\n",
    "    contTest = 0\n",
    "    trainFiles = [0] * sizeTrain\n",
    "    valFiles = [0] * sizeVal\n",
    "    testFiles = [0] * sizeTest\n",
    "    noAdd = False\n",
    "    contTestALS = 0\n",
    "    contValALS = 0\n",
    "    contFile = 0\n",
    "    addTrain = True\n",
    "    addVal = True\n",
    "    addTest = True\n",
    "    i = 0\n",
    "    while(i < len(filenames)):\n",
    "        n = random.randint(0,2)\n",
    "        if(n==0):\n",
    "            if(contTrain<sizeTrain and addTrain):\n",
    "                trainFiles[contTrain] = filenames[i] \n",
    "                trainFiles[contTrain+1] = filenames[i+1] \n",
    "                contTrain += 2\n",
    "                if(contTrain > (sizeTrain/4)+2 and contFile < 66):\n",
    "                  addTrain = False\n",
    "            else:\n",
    "                noAdd = True\n",
    "        elif(n==1):\n",
    "            if(contVal<sizeVal and addVal):\n",
    "                valFiles[contVal] = filenames[i] \n",
    "                valFiles[contVal+1] = filenames[i+1] \n",
    "                contVal += 2\n",
    "                if(contVal > sizeVal/4 and contFile < 66):\n",
    "                  addVal = False\n",
    "            else:\n",
    "                noAdd = True\n",
    "        elif(n==2):\n",
    "            if(contTest<sizeTest and addTest):\n",
    "                testFiles[contTest] = filenames[i] \n",
    "                testFiles[contTest+1] = filenames[i+1] \n",
    "                contTest += 2\n",
    "                if(contTest > sizeTest/4 and contFile < 66):\n",
    "                  addTest = False\n",
    "            else:\n",
    "                noAdd = True\n",
    "        if(noAdd):\n",
    "            if(contTrain<sizeTrain and addTrain):\n",
    "                trainFiles[contTrain] = filenames[i] \n",
    "                trainFiles[contTrain+1] = filenames[i+1] \n",
    "                contTrain += 2\n",
    "            elif(contVal<sizeVal and addTest):\n",
    "                valFiles[contVal] = filenames[i] \n",
    "                valFiles[contVal+1] = filenames[i+1] \n",
    "                contVal += 2\n",
    "            elif(contTest<sizeTest and addVal):\n",
    "                testFiles[contTest] = filenames[i] \n",
    "                testFiles[contTest+1] = filenames[i+1] \n",
    "                contTest += 2\n",
    "        noAdd = False\n",
    "        i += 2\n",
    "        contFile += 2\n",
    "        if (contFile>66 and ((not addTrain) or (not addVal) or (not addTest))):\n",
    "          addTrain = True\n",
    "          addVal = True\n",
    "          addTest = True\n",
    "    trainFiles = tf.random.shuffle(trainFiles)\n",
    "    testFiles = tf.random.shuffle(testFiles)\n",
    "    valFiles = tf.random.shuffle(valFiles)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    # Train subdataset\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(trainFiles)\n",
    "    spectrogram_ds = files_ds.map(map_func=get_spectrogram_and_label,num_parallel_calls=AUTOTUNE)\n",
    "    # Test subdataset\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(testFiles)\n",
    "    test_ds = files_ds.map(map_func=get_spectrogram_and_label,num_parallel_calls=AUTOTUNE)\n",
    "    # Validation subdataset\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(valFiles)\n",
    "    val_ds = files_ds.map(map_func=get_spectrogram_and_label,num_parallel_calls=AUTOTUNE)\n",
    "    train_ds = spectrogram_ds\n",
    "    train_ds = train_ds.batch(32)\n",
    "    val_ds = val_ds.batch(32)\n",
    "    #AÃ±adiendo cache para reducir latencia\n",
    "    train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "    for spectrogram, label in spectrogram_ds.take(1):\n",
    "        input_shape = spectrogram.shape\n",
    "    # Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "    norm_layer = layers.Normalization()\n",
    "    # Fit the state of the layer to the spectrograms\n",
    "    # with `Normalization.adapt`.\n",
    "    norm_layer.adapt(data=spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        # Downsample the input.\n",
    "        # layers.Resizing(32, 32),\n",
    "        # Normalize.\n",
    "        norm_layer,\n",
    "        layers.Conv2D(8, 3, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Conv2D(16, 3, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Conv2D(32, 3, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer='l1'),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dropout(0.6),\n",
    "        layers.Dense(2),\n",
    "    ])\n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    "    )\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=5),\n",
    "    )\n",
    "    test_audio = []\n",
    "    test_labels = []\n",
    "\n",
    "    for audio, label in test_ds:\n",
    "        test_audio.append(audio.numpy())\n",
    "        test_labels.append(label.numpy())\n",
    "\n",
    "    test_audio = np.array(test_audio)\n",
    "    test_labels = np.array(test_labels)\n",
    "    y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "    y_true = test_labels\n",
    "\n",
    "    test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "    average.append(test_acc)\n",
    "    print(f'Test set accuracy: {test_acc:.0%}')\n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.show()\n",
    "    plt.plot(history.epoch, metrics['accuracy'], metrics['val_accuracy'])\n",
    "    plt.legend(['accuracy', 'val_accuracy'])\n",
    "    plt.show()\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(confusion_mtx,\n",
    "    xticklabels=classes,\n",
    "    yticklabels=classes,\n",
    "    annot=True, fmt='g')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.show()\n",
    "print(f'Average accuracy: {np.mean(np.array(average))}')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
